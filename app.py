import streamlit as st
import os
import re # ì •ê·œí‘œí˜„ì‹ ëª¨ë“ˆ ì¶”ê°€ (í•„ìˆ˜)
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ğŸ¨ ìƒí™©ë³„ ì‘ë‹µ AI ì±—ë´‡", layout="wide")
st.title("ğŸ¤– í…ìŠ¤íŠ¸ & ì´ë¯¸ì§€ ìƒì„± ì±—ë´‡")

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ë° ë³€ìˆ˜ ì •ë¦¬
AZURE_OAI_KEY = os.getenv("AZURE_OAI_KEY")
AZURE_OAI_ENDPOINT = os.getenv("AZURE_OAI_ENDPOINT")
OAI_DEPLOYMENT = "gpt-4o-mini" 

# ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ìœ„í•œ GPT í´ë¼ì´ì–¸íŠ¸
client = AzureOpenAI(
    api_key=AZURE_OAI_KEY,
    api_version="2024-05-01-preview",
    azure_endpoint=AZURE_OAI_ENDPOINT
)

# DALL-E ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# (ë³´ì•ˆì„ ìœ„í•´ ì—”ë“œí¬ì¸íŠ¸ì™€ í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.)
dalle_deployment = "dall-e-3" 
create_img_client = AzureOpenAI(
    api_version="2024-04-01-preview",
    # í•˜ë“œì½”ë”©ëœ ì£¼ì†Œë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ëŒ€ì²´ ê¶Œì¥
    azure_endpoint="https://el22-mieta6ou-australiaeast.cognitiveservices.azure.com/",
    api_key=os.getenv("OTHER_KEY"),
)

# 3. ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™” ë° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
if "messages" not in st.session_state:
    st.session_state.messages = []
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: AIì˜ ì´ë¯¸ì§€ ìƒì„± ê·œì¹™ì„ ëª…í™•íˆ ì •ì˜
    st.session_state.system_prompt = {
        "role": "system",
        "content": "ë‹¹ì‹ ì€ ë§ŒëŠ¥ ë¹„ì„œì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ 'ê·¸ë ¤ì¤˜', 'ì´ë¯¸ì§€', 'ì‚¬ì§„', 'ìƒì„±' ë“±ì˜ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë¦¼ ìš”ì²­ì„ í•˜ë©´, ìš”ì²­ ë‚´ìš© ì¤‘ í•µì‹¬ í‚¤ì›Œë“œë§Œì„ ì¶”ì¶œí•˜ì—¬ **[IMAGE: í‚¤ì›Œë“œ]** í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. ì˜ˆì‹œ: 'ê³ ì–‘ì´ ê·¸ë ¤ì¤˜' -> '[IMAGE: ê·€ì—¬ìš´ ê³ ì–‘ì´]', ê·¸ ì™¸ì˜ ì§ˆë¬¸ì—ëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
    }
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ëŒ€í™” ëª©ë¡ ë§¨ ì•ì— ì¶”ê°€ (ë‹¨, í•œ ë²ˆë§Œ)
    st.session_state.messages.append(st.session_state.system_prompt)


# 4. í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” í™”ë©´ì— ì¶œë ¥í•˜ì§€ ì•ŠìŒ
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            # ì €ì¥ëœ ë‚´ìš©ì´ ì´ë¯¸ì§€ URLì¸ ê²½ìš° st.imageë¡œ ì¶œë ¥
            if message["role"] == "assistant" and message["content"].startswith("http"):
                st.image(message["content"], caption="AIê°€ ìƒì„±í•œ ì´ë¯¸ì§€")
            else:
                st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):

    # 5-1. ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ ë° ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 5-2. LLM ì‘ë‹µ ìƒì„± (ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ í¬í•¨)
    with st.chat_message("assistant"):
        # ëª¨ë¸ì— ì „ë‹¬í•  ì „ì²´ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
        model_messages = [
            {"role": m["role"], "content": m["content"]}
            for m in st.session_state.messages
        ]

        # 1ì°¨ í˜¸ì¶œ: LLMì´ í…ìŠ¤íŠ¸ ë˜ëŠ” [IMAGE:...] íŒ¨í„´ì„ ë°˜í™˜í•˜ë„ë¡ ìš”ì²­
        response = client.chat.completions.create(
            model=OAI_DEPLOYMENT, 
            messages=model_messages
        )
        assistant_reply = response.choices[0].message.content

        # 6. ì´ë¯¸ì§€ ìƒì„± íŒë‹¨ ë° ì²˜ë¦¬ ë¡œì§

        # [IMAGE: ...] íŒ¨í„´ì„ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ìŒ)
        image_match = re.search(r"\[IMAGE:\s*(.*?)\]", assistant_reply, re.IGNORECASE)

        if image_match:
            # ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ì´ íƒì§€ë¨
            image_prompt = image_match.group(1).strip()

            # ì‚¬ìš©ìì—ê²Œ ì´ë¯¸ì§€ ìƒì„± ì¤‘ì„ì„ ì•Œë¦¼
            with st.spinner(f"ğŸ¨ '{image_prompt}'(ìœ¼)ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):

                try:
                    # DALL-E ëª¨ë¸ í˜¸ì¶œ
                    img_response = create_img_client.images.generate(
                        model=dalle_deployment,
                        prompt=image_prompt,
                        size="1024x1024",
                        n=1,
                    )

                    # ìƒì„±ëœ ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
                    image_url = img_response.data[0].url

                    # Streamlitì— ì´ë¯¸ì§€ í‘œì‹œ
                    st.image(image_url, caption=f"'{image_prompt}' ì´ë¯¸ì§€")

                    # ìµœì¢… ì‘ë‹µì„ ì´ë¯¸ì§€ URLë¡œ ì €ì¥
                    final_response = image_url

                except Exception as e:
                    error_msg = f"âŒ ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. DALL-E API ì˜¤ë¥˜: {e}"
                    st.error(error_msg)
                    final_response = error_msg

        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ
            st.markdown(assistant_reply)
            final_response = assistant_reply

    # 7. AI ì‘ë‹µ ì €ì¥ (ì´ë¯¸ì§€ URL ë˜ëŠ” í…ìŠ¤íŠ¸)
    st.session_state.messages.append({"role": "assistant", "content": final_response})
